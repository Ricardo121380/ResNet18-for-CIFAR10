{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-19T13:59:33.796741Z","iopub.execute_input":"2024-04-19T13:59:33.797134Z","iopub.status.idle":"2024-04-19T13:59:34.620630Z","shell.execute_reply.started":"2024-04-19T13:59:33.797104Z","shell.execute_reply":"2024-04-19T13:59:34.619857Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"%%time\nimport torch\nimport torchvision\nimport torchvision.transforms as transforms\nfrom torchvision.transforms import RandomCrop\nfrom torch.utils.data import DataLoader\nfrom torchvision.models import resnet18\nimport torch.nn as nn\nimport torch.optim as optim\nimport numpy as np\nfrom sklearn.manifold import TSNE\nfrom sklearn.metrics import confusion_matrix\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Data preprocessing\ntransform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomCrop(32,padding=4),\n    #Cutout(n_holes=1, length=16)\n    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n])\n\n# Load dataset\ntrainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\ntrainloader = DataLoader(trainset, batch_size=16, shuffle=True, num_workers=2)\ntestset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\ntestloader = DataLoader(testset, batch_size=16, shuffle=False, num_workers=2)\n\n# Model setup\nmodel = resnet18()\nnum_ftrs = model.fc.in_features\nmodel.fc = nn.Linear(num_ftrs, 10)  # Adapt the classifier for CIFAR-10\n\nif torch.cuda.is_available():\n    model.cuda()\n\n# Loss and optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\nscheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n\n# Training the model\ndef train_model(num_epochs):\n    for epoch in range(num_epochs):\n        model.train()  # Ensure the model is in training mode\n        running_loss = 0.0\n        total_batches = 0\n        \n        for inputs, labels in trainloader:\n            if torch.cuda.is_available():\n                inputs, labels = inputs.cuda(), labels.cuda()\n\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n            running_loss += loss.item()\n            total_batches += 1\n\n        epoch_loss = running_loss / total_batches\n        print(f'Epoch {epoch + 1}: Training Loss: {epoch_loss:.4f}')\n        scheduler.step()\n        \n        # Evaluate at the end of each epoch\n        evaluate_model(epoch + 1)\n\n    print('Finished Training')\n\n# Feature extraction for t-SNE\ndef extract_features():\n    model.eval()\n    features = []\n    labels = []\n    with torch.no_grad():\n        for data in testloader:\n            inputs, label = data\n            if torch.cuda.is_available():\n                inputs = inputs.cuda()\n            output = model(inputs)\n            features.extend(output.cpu().detach().numpy())\n            labels.extend(label.numpy())\n\n    return np.array(features), np.array(labels)\n\n# Plotting t-SNE\ndef plot_tsne(features, labels):\n    tsne = TSNE(n_components=2, random_state=0)\n    tsne_results = tsne.fit_transform(features)\n\n    plt.figure(figsize=(12, 8))\n    scatter = plt.scatter(tsne_results[:, 0], tsne_results[:, 1], c=labels, cmap='tab10', alpha=0.6)\n    plt.colorbar(scatter)\n    plt.title('t-SNE visualization of CIFAR-10 Features')\n    plt.show()\n\n# Accuracy\ndef evaluate_model(epoch):\n    model.eval()  # Set the model to evaluation mode\n    val_loss = 0\n    correct = 0\n    total = 0\n\n    with torch.no_grad():\n        for inputs, labels in testloader:\n            if torch.cuda.is_available():\n                inputs, labels = inputs.cuda(), labels.cuda()\n\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            val_loss += loss.item() * inputs.size(0)\n\n            _, predicted = torch.max(outputs, 1)\n            correct += (predicted == labels).sum().item()\n            total += labels.size(0)\n\n    avg_loss = val_loss / total\n    accuracy = correct / total\n    print(f'Epoch {epoch}: Validation Loss: {avg_loss:.4f}, Accuracy: {accuracy:.4f}')\n\n# Confuison matrix\ndef plot_confusion_matrix():\n    model.eval()\n    gt_labels = []\n    pred_labels = []\n\n    with torch.no_grad():\n        for inputs, labels in testloader:\n            if torch.cuda.is_available():\n                inputs = inputs.cuda()\n\n            outputs = model(inputs)\n            _, predicted = torch.max(outputs, 1)\n            gt_labels.append(labels.cpu().numpy())\n            pred_labels.append(predicted.cpu().numpy())\n\n    gt_labels = np.concatenate(gt_labels)\n    pred_labels = np.concatenate(pred_labels)\n    cm = confusion_matrix(gt_labels, pred_labels)\n    accuracy = np.trace(cm) / np.sum(cm)\n    print(f'Accuracy of the network on the 10000 test images: {accuracy * 100:.2f}%')\n\n\n    plt.figure(figsize=(10, 8))\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=trainset.classes, yticklabels=trainset.classes)\n    plt.xlabel('Predicted')\n    plt.ylabel('Actual')\n    plt.title('Final Confusion Matrix')\n    plt.show()\n\n# Main execution\nnum_epochs = 100\ntrain_model(num_epochs)\nfeatures, labels = extract_features()\nplot_tsne(features, labels)\nplot_confusion_matrix()\n","metadata":{"execution":{"iopub.status.busy":"2024-04-19T13:59:34.621979Z","iopub.execute_input":"2024-04-19T13:59:34.622381Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 170498071/170498071 [00:04<00:00, 40363739.57it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracting ./data/cifar-10-python.tar.gz to ./data\nFiles already downloaded and verified\nEpoch 1: Training Loss: 1.7578\nEpoch 1: Validation Loss: 1.4732, Accuracy: 0.4609\nEpoch 2: Training Loss: 1.4429\nEpoch 2: Validation Loss: 1.2475, Accuracy: 0.5467\nEpoch 3: Training Loss: 1.2743\nEpoch 3: Validation Loss: 1.1160, Accuracy: 0.5993\nEpoch 4: Training Loss: 1.1561\nEpoch 4: Validation Loss: 1.0305, Accuracy: 0.6391\n","output_type":"stream"}]}]}